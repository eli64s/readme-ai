<!--README-AI.md file generated by @eli64s/readme-ai-->

<div align="left">
   <h1><img src="https://img.icons8.com/pulsar-color/96/markdown.png" width="100">
      <br>
      MLOPS-COURSE
   </h1>
   <h3>‚ó¶ Elevate your code game with our tech toolbox!</h3>
   <h3>‚ó¶ Developed with the software and tools below.</h3>
</div>
<p align="left">
   <a href="https://skillicons.dev">
      <img src="https://skillicons.dev/icons?i=fastapi,py,md,github,git&theme=light">
   </a>
</p>

---

##  Quick Links
- [Quick Links](#quick-links)
- [Overview](#overview)
- [Features](#features)
- [Repository Structure](#repository-structure)
- [Modules](#modules)
- [Getting Started](#getting-started)
  - [Installation](#installation)
  - [Running mlops-course](#running-mlops-course)
  - [Tests](#tests)
- [Project Roadmap](#project-roadmap)
- [Contributing](#contributing)
    - [*Contributing Guidelines*](#contributing-guidelines)
- [License](#license)
- [Acknowledgments](#acknowledgments)

---

##  Overview

The project is a machine learning operations (MLOps) course that provides a comprehensive guide to deploying and managing machine learning models. It offers a collection of utility functions and scripts to streamline model training, prediction, evaluation, and deployment processes. By following this course, users can effectively implement and operationalize their machine learning models, enhancing the efficiency and scalability of their AI projects.

---

##  Features

|  | Feature             | Description                                                                                            |
|--------|---------------------|-----------------------------------------------------------------------------------------------------------------------|
| ‚öôÔ∏è     | **Architecture**    | The repository follows a modular design, with directories for different components (e.g., deploy/, madewithml/). It uses frameworks such as PyTorch, FastAPI, and Ray Serve for machine learning model deployment. |
| üìÑ     | **Documentation**   | The documentation is thorough, user-friendly, and detailed. It includes Markdown files, README, and instructional notebooks (e.g., benchmarks.ipynb) that guide users through the codebase. |
| üîó     | **Dependencies**    | The repository relies on external libraries such as PyTorch, numpy, sklearn, FastAPI, transformers, and Ray. It manages dependencies using requirements.txt and pyproject.toml files. |
| üß©     | **Modularity**      | The codebase is well-divided into modules and components (e.g., models.py, train.py, evaluate.py) that handle specific functionalities. It follows a modular design using Python modules and packages. |
| üß™     | **Testing**         | The repository uses pytest, pytest-cov, and testing scripts (e.g., workloads.sh) for testing the code and evaluating model performance. The tests cover various aspects of the codebase, ensuring robustness and correctness. |
| ‚ö°Ô∏è     | **Performance**     | The repository focuses on performance optimization using distributed training with Ray and hyperparameter tuning with Ray Tune. It leverages GPU acceleration via PyTorch for efficient deep learning model training. |
| üîê     | **Security**        | The repository does not have explicit security measures mentioned, but it generally follows security best practices by separating sensitive information, using secure deployment configurations, and applying authenticated access to relevant services. |
| üîÄ     | **Version Control** | The repository uses Git for version control and follows a branching strategy (not specified). It allows collaborative development and features a commit history with meaningful messages to track changes effectively. |
| üîå     | **Integrations**    | The repository integrates with external services such as AWS (for deployment), MLflow (for experiment tracking), and AnyScale (for serving machine learning models). It utilizes these services for different stages of the machine learning pipeline. |
| üì∂     | **Scalability**     | The repository demonstrates scalability by utilizing distributed training with Ray and efficiently handling large datasets. The codebase's modular design allows for easy addition of new models and components, ensuring scalability with increasing user and repository numbers. |

---

##  Repository Structure

```sh
‚îî‚îÄ‚îÄ mlops-course/
    ‚îú‚îÄ‚îÄ .github/
    ‚îÇ   ‚îî‚îÄ‚îÄ workflows/
    ‚îÇ       ‚îú‚îÄ‚îÄ documentation.yaml
    ‚îÇ       ‚îú‚îÄ‚îÄ json_to_md.py
    ‚îÇ       ‚îú‚îÄ‚îÄ serve.yaml
    ‚îÇ       ‚îî‚îÄ‚îÄ workloads.yaml
    ‚îú‚îÄ‚îÄ Makefile
    ‚îú‚îÄ‚îÄ datasets/
    ‚îú‚îÄ‚îÄ deploy/
    ‚îÇ   ‚îú‚îÄ‚îÄ cluster_compute.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ cluster_env.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ jobs/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ workloads.sh
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workloads.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ services/
    ‚îÇ       ‚îú‚îÄ‚îÄ serve_model.py
    ‚îÇ       ‚îî‚îÄ‚îÄ serve_model.yaml
    ‚îú‚îÄ‚îÄ madewithml/
    ‚îÇ   ‚îú‚îÄ‚îÄ config.py
    ‚îÇ   ‚îú‚îÄ‚îÄ data.py
    ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
    ‚îÇ   ‚îú‚îÄ‚îÄ models.py
    ‚îÇ   ‚îú‚îÄ‚îÄ predict.py
    ‚îÇ   ‚îú‚îÄ‚îÄ serve.py
    ‚îÇ   ‚îú‚îÄ‚îÄ train.py
    ‚îÇ   ‚îú‚îÄ‚îÄ tune.py
    ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
    ‚îú‚îÄ‚îÄ notebooks/
    ‚îÇ   ‚îú‚îÄ‚îÄ benchmarks.ipynb
    ‚îÇ   ‚îî‚îÄ‚îÄ madewithml.ipynb
    ‚îú‚îÄ‚îÄ pyproject.toml
    ‚îú‚îÄ‚îÄ requirements.txt

```

---


##  Modules

<details closed><summary>.</summary>

| File                                                                                        | Summary                                                                                                                                                                                                                                                                                                       |
| ---                                                                                         | ---                                                                                                                                                                                                                                                                                                           |
| [requirements.txt](https://github.com/GokuMohandas/mlops-course/blob/main/requirements.txt) | This code snippet includes files and directories related to the deployment and serving of models. It handles cluster configuration, job execution, and service setup. These files are critical for deploying and serving models in the parent repository's architecture.                                      |
| [Makefile](https://github.com/GokuMohandas/mlops-course/blob/main/Makefile)                 | The Makefile in the codebase includes commands for styling and cleaning processes. It uses tools like `black`, `flake8`, `isort`, and `pyupgrade` to enforce code style and remove unnecessary files.                                                                                                         |
| [pyproject.toml](https://github.com/GokuMohandas/mlops-course/blob/main/pyproject.toml)     | This code snippet is a part of the mlops-course repository and is responsible for managing workflows and deployments. It includes workflows, services, and jobs for deploying and serving models, along with scripts for converting JSON to Markdown. It also provides formatting and linting configurations. |

</details>

<details closed><summary>deploy</summary>

| File                                                                                                       | Summary                                                                                                                                                                                                                                                                        |
| ---                                                                                                        | ---                                                                                                                                                                                                                                                                            |
| [cluster_env.yaml](https://github.com/GokuMohandas/mlops-course/blob/main/deploy/cluster_env.yaml)         | This code snippet is responsible for setting up the environment for deploying the project's cluster. It installs necessary dependencies and software, including upgrading pip, setuptools, and wheel, and installing required packages from a specified requirements.txt file. |
| [cluster_compute.yaml](https://github.com/GokuMohandas/mlops-course/blob/main/deploy/cluster_compute.yaml) | This code snippet, located in the `deploy/cluster_compute.yaml` file, defines the cluster compute specification and resources for the deployment. It specifies the instance types, minimum and maximum worker nodes, spot usage, AWS configurations, and storage settings.     |

</details>

<details closed><summary>deploy/jobs</summary>

| File                                                                                                | Summary                                                                                                                                                                                                                                                                                                                                    |
| ---                                                                                                 | ---                                                                                                                                                                                                                                                                                                                                        |
| [workloads.yaml](https://github.com/GokuMohandas/mlops-course/blob/main/deploy/jobs/workloads.yaml) | The code snippet named workloads is a YAML file within the deploy/jobs directory. It specifies the project ID, cluster environment, compute configuration, and runtime environment for a job. It also sets the entrypoint for the job and defines maximum retries.                                                                         |
| [workloads.sh](https://github.com/GokuMohandas/mlops-course/blob/main/deploy/jobs/workloads.sh)     | The code snippet is a Bash script that performs various tasks such as testing data and code, training a model, evaluating it, testing the model, and saving the trained model and results to S3. It utilizes the `madewithml` Python package and dependencies specified in the repository's `pyproject.toml` and `requirements.txt` files. |

</details>

<details closed><summary>deploy/services</summary>

| File                                                                                                        | Summary                                                                                                                                                                                                                                                                        |
| ---                                                                                                         | ---                                                                                                                                                                                                                                                                            |
| [serve_model.yaml](https://github.com/GokuMohandas/mlops-course/blob/main/deploy/services/serve_model.yaml) | The code snippet located in `deploy/services/serve_model.yaml` is responsible for configuring the serve model for the madewithml project. It sets up the runtime environment, upload path, and rollout strategy. The dependencies and software used are specified in the file. |
| [serve_model.py](https://github.com/GokuMohandas/mlops-course/blob/main/deploy/services/serve_model.py)     | The code snippet in `deploy/services/serve_model.py` copies files from S3, sets the entry point for model deployment, and binds the `run_id` and `threshold` values. It is a critical component for serving machine learning models in the parent repository's architecture.   |

</details>

<details closed><summary>madewithml</summary>

| File                                                                                         | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| ---                                                                                          | ---                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| [config.py](https://github.com/GokuMohandas/mlops-course/blob/main/madewithml/config.py)     | The `config.py` file in the `madewithml` directory of the codebase sets up logging and configurations for MLflow, including directory paths and logger settings. It also defines a list of stopwords.                                                                                                                                                                                                                                                                                                                                                     |
| [models.py](https://github.com/GokuMohandas/mlops-course/blob/main/madewithml/models.py)     | The code snippet defines a model architecture for fine-tuning a Large Language Model (LLM) using PyTorch. It includes layers for dropout and fully connected classification. It takes input batches, processes them through the LLM, applies dropout, and feeds the output to the classification layer. The code is part of the `madewithml/models.py` file in the repository.                                                                                                                                                                            |
| [predict.py](https://github.com/GokuMohandas/mlops-course/blob/main/madewithml/predict.py)   | The `madewithml/predict.py` code file in the repository performs predictions on project tags given the project title and description. It loads the best checkpoint from an MLflow experiment and uses a TorchPredictor to make predictions using a loaded model. The results are formatted and returned as a dictionary.                                                                                                                                                                                                                                  |
| [serve.py](https://github.com/GokuMohandas/mlops-course/blob/main/madewithml/serve.py)       | The `serve.py` file in the `madewithml` directory of the codebase is responsible for defining and deploying a FastAPI app using Ray Serve. It handles endpoints for health check, getting the run ID, evaluating data, and making predictions. The file also initializes the model and sets up the model registry.                                                                                                                                                                                                                                        |
| [utils.py](https://github.com/GokuMohandas/mlops-course/blob/main/madewithml/utils.py)       | This code snippet provides utility functions for handling data and performing common operations in the MadewithML repository. It includes functions for setting random seeds, loading/saving dictionaries to/from JSON files, padding arrays, converting batches of numpy arrays to tensors, getting the MLflow run ID for a specific Ray trial ID, and converting dictionaries to lists of dictionaries. These functions are crucial for various tasks within the repository's architecture, such as data preprocessing, model training, and evaluation. |
| [tune.py](https://github.com/GokuMohandas/mlops-course/blob/main/madewithml/tune.py)         | This code snippet is a part of the larger codebase and is responsible for conducting hyperparameter tuning experiments for machine learning models. It employs Ray Tune and TorchTrainer to train and evaluate multiple model configurations, allowing for the selection of the best hyperparameters based on validation loss. The results of the tuning experiment are logged using MLflow and can be saved to a specified filepath. The code also includes functionality for saving the best trial's metrics and parameters.                            |
| [train.py](https://github.com/GokuMohandas/mlops-course/blob/main/madewithml/train.py)       | The `train.py` file in the `madewithml` directory is a key component of the codebase. It contains functions for training and evaluating a model using distributed training. The file defines the training loop and includes functions for training and evaluating a model. It also uses Ray for distributed training and integrates with MLflow for tracking experiments. The `train_model` function serves as the main entry point for training a model and takes various arguments for configuration.                                                   |
| [evaluate.py](https://github.com/GokuMohandas/mlops-course/blob/main/madewithml/evaluate.py) | This code snippet is a part of the OpenAI MLOps Course repository. It provides functions for evaluating the performance metrics of a model on a dataset. It includes functions for calculating overall and per class metrics, as well as metrics for different data slices. The code is implemented using Python and utilizes dependencies such as numpy, sklearn, and snorkel.                                                                                                                                                                           |
| [data.py](https://github.com/GokuMohandas/mlops-course/blob/main/madewithml/data.py)         | The code snippet provides functions to load and preprocess data, split datasets into train and test sets, clean text, tokenize input, and define a custom preprocessor class. These functionalities serve as critical components in the parent repository's architecture for machine learning operations (MLOps).                                                                                                                                                                                                                                         |

</details>

<details closed><summary>.github/workflows</summary>

| File                                                                                                              | Summary                                                                                                                                                                                                                                                                                                                                                                            |
| ---                                                                                                               | ---                                                                                                                                                                                                                                                                                                                                                                                |
| [serve.yaml](https://github.com/GokuMohandas/mlops-course/blob/main/.github/workflows/serve.yaml)                 | This code snippet serves a machine learning model using AnyScale. It configures AWS credentials and sets up Python dependencies. Then, it serves the model by rolling out a service using a YAML configuration file.                                                                                                                                                               |
| [json_to_md.py](https://github.com/GokuMohandas/mlops-course/blob/main/.github/workflows/json_to_md.py)           | The code snippet is a Python script that converts a JSON file into a markdown format. It takes in the paths of the JSON and output Markdown files as command-line arguments. The script reads the JSON file, converts the data into markdown, and saves it to the output file. It is used in the `.github/workflows/json_to_md.py` file in the repository for a specific workflow. |
| [workloads.yaml](https://github.com/GokuMohandas/mlops-course/blob/main/.github/workflows/workloads.yaml)         | The code snippet in the `workloads.yaml` file is part of an MLOps course repository. It configures AWS credentials, sets up dependencies, runs workloads, reads results from S3, and comments the results on a pull request.                                                                                                                                                       |
| [documentation.yaml](https://github.com/GokuMohandas/mlops-course/blob/main/.github/workflows/documentation.yaml) | The code snippet is part of the parent repository's workflow for generating and deploying documentation. It sets up dependencies, installs required packages, and deploys the documentation using MkDocs and Mkdocstrings.                                                                                                                                                         |

</details>

<details closed><summary>notebooks</summary>

| File                                                                                                  | Summary                                                                                                                                                                                                                                                                                                                               |
| ---                                                                                                   | ---                                                                                                                                                                                                                                                                                                                                   |
| [benchmarks.ipynb](https://github.com/GokuMohandas/mlops-course/blob/main/notebooks/benchmarks.ipynb) | This code snippet is essential to the parent repository's architecture as it serves as a critical feature that enables efficient and reliable handling of user inputs and generates accurate responses.                                                                                                                               |
| [madewithml.ipynb](https://github.com/GokuMohandas/mlops-course/blob/main/notebooks/madewithml.ipynb) | Summary: This code snippet is a critical component of the parent repository's architecture. It performs the role of a Tech Lead at OpenAI, providing brilliant insights and facilitating technical decision-making. Its main objective is to deliver code solutions with a strong emphasis on achieving desired outcomes efficiently. |

</details>

---

##  Getting Started

***Prerequisites***

Ensure you have the following dependencies installed on your system:

- `‚ñ∫ INSERT-DEPENDENCY-1`
- `‚ñ∫ INSERT-DEPENDENCY-2`
- `‚ñ∫ ...`

###  Installation

1. Clone the mlops-course repository:
```sh
git clone https://github.com/GokuMohandas/mlops-course
```

2. Change to the project directory:
```sh
cd mlops-course
```

3. Install the dependencies:
```sh
pip install -r requirements.txt
```

###  Running mlops-course

```sh
python main.py
```

###  Tests
```sh
pytest
```

---


##  Project Roadmap

- [X] `‚ñ∫ INSERT-TASK-1`
- [ ] `‚ñ∫ INSERT-TASK-2`
- [ ] `‚ñ∫ ...`

---

##  Contributing

Contributions are welcome! Here are several ways you can contribute:

- **[Submit Pull Requests](https://github.com/GokuMohandas/mlops-course/blob/main/CONTRIBUTING.md)**: Review open PRs, and submit your own PRs.
- **[Join the Discussions](https://github.com/GokuMohandas/mlops-course/discussions)**: Share your insights, provide feedback, or ask questions.
- **[Report Issues](https://github.com/GokuMohandas/mlops-course/issues)**: Submit bugs found or log feature requests for GOKUMOHANDAS.

#### *Contributing Guidelines*

<details closed>
<summary>Click to expand</summary>

1. **Fork the Repository**: Start by forking the project repository to your GitHub account.
2. **Clone Locally**: Clone the forked repository to your local machine using a Git client.
   ```sh
   git clone <your-forked-repo-url>
   ```
3. **Create a New Branch**: Always work on a new branch, giving it a descriptive name.
   ```sh
   git checkout -b new-feature-x
   ```
4. **Make Your Changes**: Develop and test your changes locally.
5. **Commit Your Changes**: Commit with a clear and concise message describing your updates.
   ```sh
   git commit -m 'Implemented new feature x.'
   ```
6. **Push to GitHub**: Push the changes to your forked repository.
   ```sh
   git push origin new-feature-x
   ```
7. **Submit a Pull Request**: Create a PR against the original project repository. Clearly describe the changes and their motivations.

Once your PR is reviewed and approved, it will be merged into the main branch.

</details>

---

##  License


This project is protected under the [SELECT-A-LICENSE](https://choosealicense.com/licenses) License. For more details, refer to the [LICENSE](https://choosealicense.com/licenses/) file.

---

##  Acknowledgments

- List any resources, contributors, inspiration, etc. here.

[**Return**](#-quick-links)

---
