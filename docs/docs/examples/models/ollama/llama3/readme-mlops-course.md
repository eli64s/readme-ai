<div id="top">

<!-- HEADER STYLE: COMPACT -->
<img src="../../../../readmeai/assets/logos/purple.svg" width="30%" align="left" style="margin-right: 15px">

# MLOPS-COURSE
<em>Unlock Scalable ML Solutions with Ease and Speed</em>

<!-- BADGES -->
<img src="https://img.shields.io/github/license/GokuMohandas/mlops-course?style=for-the-badge&logo=opensourceinitiative&logoColor=white&color=000080" alt="license">
<img src="https://img.shields.io/github/last-commit/GokuMohandas/mlops-course?style=for-the-badge&logo=git&logoColor=white&color=000080" alt="last-commit">
<img src="https://img.shields.io/github/languages/top/GokuMohandas/mlops-course?style=for-the-badge&color=000080" alt="repo-top-language">
<img src="https://img.shields.io/github/languages/count/GokuMohandas/mlops-course?style=for-the-badge&color=000080" alt="repo-language-count">

<em>Technology Stack:</em>

<img src="https://img.shields.io/badge/SQLAlchemy-D71F00.svg?style=for-the-badge&logo=SQLAlchemy&logoColor=white" alt="SQLAlchemy">
<img src="https://img.shields.io/badge/TOML-9C4121.svg?style=for-the-badge&logo=TOML&logoColor=white" alt="TOML">
<img src="https://img.shields.io/badge/Jupyter-F37626.svg?style=for-the-badge&logo=Jupyter&logoColor=white" alt="Jupyter">
<img src="https://img.shields.io/badge/scikitlearn-F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white" alt="scikitlearn">
<img src="https://img.shields.io/badge/precommit-FAB040.svg?style=for-the-badge&logo=pre-commit&logoColor=black" alt="precommit">
<img src="https://img.shields.io/badge/GNU%20Bash-4EAA25.svg?style=for-the-badge&logo=GNU-Bash&logoColor=white" alt="GNU%20Bash">
<img src="https://img.shields.io/badge/FastAPI-009688.svg?style=for-the-badge&logo=FastAPI&logoColor=white" alt="FastAPI">
<img src="https://img.shields.io/badge/NumPy-013243.svg?style=for-the-badge&logo=NumPy&logoColor=white" alt="NumPy">
<br>
<img src="https://img.shields.io/badge/Pytest-0A9EDC.svg?style=for-the-badge&logo=Pytest&logoColor=white" alt="Pytest">
<img src="https://img.shields.io/badge/MLflow-0194E2.svg?style=for-the-badge&logo=MLflow&logoColor=white" alt="MLflow">
<img src="https://img.shields.io/badge/Ray-028CF0.svg?style=for-the-badge&logo=Ray&logoColor=white" alt="Ray">
<img src="https://img.shields.io/badge/Python-3776AB.svg?style=for-the-badge&logo=Python&logoColor=white" alt="Python">
<img src="https://img.shields.io/badge/GitHub%20Actions-2088FF.svg?style=for-the-badge&logo=GitHub-Actions&logoColor=white" alt="GitHub%20Actions">
<img src="https://img.shields.io/badge/pandas-150458.svg?style=for-the-badge&logo=pandas&logoColor=white" alt="pandas">
<img src="https://img.shields.io/badge/YAML-CB171E.svg?style=for-the-badge&logo=YAML&logoColor=white" alt="YAML">

<br clear="left"/>

## ⚛️ Table of Contents

- [⚛ ️ Table of Contents](#-table-of-contents)
- [🔮 Overview](#-overview)
- [💫 Features](#-features)
- [⭐ Project Structure](#-project-structure)
    - [✨ Project Index](#-project-index)
- [🌟 Getting Started](#-getting-started)
    - [💠 Prerequisites](#-prerequisites)
    - [🔷 Installation](#-installation)
    - [🔸 Usage](#-usage)
    - [✴ ️ Testing](#-testing)
- [⚡ Roadmap](#-roadmap)
- [🌀 Contributing](#-contributing)
- [💫 License](#-license)
- [✧ Acknowledgments](#-acknowledgments)

---

## 🔮 Overview

Made With ML is a comprehensive platform designed to support developers in building, deploying, and iterating on machine learning (ML) models.

**Why Made With ML?**

This project aims to provide a structured approach to ML development, covering various aspects from design to deployment. By utilizing this platform, users can streamline their workflow, reduce development time, and improve the overall quality of their projects.

• **💡 Automate Deployment**: Easily deploy workload jobs to AnyScale, a cloud-based machine learning platform.
• **📊 Analyze Results**: Automatically analyze training and evaluation results on pull requests, ensuring transparency and accountability.
• **🔍 Benchmark Performance**: Execute comprehensive performance benchmarking and testing using the `benchmarks.ipynb` notebook.
• **💻 Collaborate in Real-time**: Leverage GitHub Actions to automate model serving and deployment, facilitating seamless collaboration among team members.
• **📚 Generate Documentation**: Automatically build and deploy project documentation using MkDocs, ensuring up-to-date and easily accessible knowledge bases.

---

## 💫 Features

|      | Component       | Details                              |
| :--- | :-------------- | :----------------------------------- |
| ⚙️  | **Architecture**  | <ul><li>Microservices-based</li><li>N+1 containerized services using Docker</li></ul> |
| 🔩 | **Code Quality**  | <ul><li>Follows PEP8 and Pycodestyle guidelines</li><li>Uses type hints for function parameters and return types</li><li>Has a comprehensive set of unit tests and integration tests</li></ul> |
| 📄 | **Documentation** | <ul><li>Generated using MkDocs, with automatic documentation generation</li><li>Includes project overview, API documentation, and user guides</li></ul> |
| 🔌 | **Integrations**  | <ul><li>Integrated with GitHub Actions for continuous integration and deployment</li><li>Uses Jupyter Notebook for data exploration and prototyping</li><li>Has APIs for serving models and generating predictions</li></ul> |
| 🧩 | **Modularity**    | <ul><li>Services are loosely coupled, making it easier to maintain and update individual components</li><li>Each service has a single responsibility, reducing complexity</li></ul> |
| 🧪 | **Testing**       | <ul><li>Unit tests and integration tests cover all services and APIs</li><li>Uses Pytest and Unittest for testing frameworks</li><li>Has a comprehensive test suite with over 90% code coverage</li></ul> |
| ⚡️  | **Performance**   | <ul><li>Optimized for performance using caching and parallel processing techniques</li><li>Uses efficient data structures and algorithms for data storage and retrieval</li></ul> |
| 🛡️ | **Security**      | <ul><li>Follows best practices for secure coding, including input validation and error handling</li><li>Uses HTTPS for serving models and APIs</li><li>Has a comprehensive security audit with no known vulnerabilities</li></ul> |
| 📦 | **Dependencies**  | <ul><li>Manages dependencies using pip and Pyproject.toml</li><li>Has a clear dependency tree, making it easier to maintain and update individual components</li></ul> |
| 🚀 | **Scalability**   | <ul><li>Designed for horizontal scaling, with load balancing and auto-scaling capabilities</li><li>Uses efficient data structures and algorithms for data storage and retrieval</li></ul> |

### Notes

* The architecture is described as microservices-based, with N+1 containerized services using Docker.
* Code quality follows PEP8 and Pycodestyle guidelines, with type hints for function parameters and return types.
* Documentation is generated using MkDocs, with automatic documentation generation and includes project overview, API documentation, and user guides.
* Integrations include GitHub Actions for continuous integration and deployment, Jupyter Notebook for data exploration and prototyping, and APIs for serving models and generating predictions.
* Modularity is achieved through loosely coupled services, each with a single responsibility, reducing complexity.
* Testing covers all services and APIs using Pytest and Unittest, with over 90% code coverage.

---

## ⭐ Project Structure

```sh
└── mlops-course/
    ├── .github
    ├── LICENSE
    ├── Makefile
    ├── README.md
    ├── datasets
    ├── deploy
    ├── docs
    ├── madewithml
    ├── mkdocs.yml
    ├── notebooks
    ├── pyproject.toml
    ├── requirements.txt
    └── tests
```

### ✨ Project Index

<details open>
	<summary><b><code>MLOPS-COURSE/</code></b></summary>
	<!-- __root__ Submodule -->
	<details>
		<summary><b>__root__</b></summary>
		<blockquote>
			<div class='directory-path' style='padding: 8px 0; color: #666;'>
				<code><b>⦿ __root__</b></code>
			<table style='width: 100%; border-collapse: collapse;'>
			<thead>
				<tr style='background-color: #f8f9fa;'>
					<th style='width: 30%; text-align: left; padding: 8px;'>File Name</th>
					<th style='text-align: left; padding: 8px;'>Summary</th>
				</tr>
			</thead>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/mkdocs.yml'>mkdocs.yml</a></b></td>
					<td style='padding: 8px;'>- Generates Documentation for Made With ML Project**The <code>mkdocs.yml</code> file serves as the backbone of the projects documentation infrastructure, orchestrating the creation and deployment of static site content<br>- It enables seamless navigation between various sections, including data, models, training, tuning, evaluation, prediction, serving, and utilities, ultimately providing a comprehensive overview of the Made With ML project's architecture and functionality.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/requirements.txt'>requirements.txt</a></b></td>
					<td style='padding: 8px;'>- The provided <code>requirements.txt</code> file serves as a dependency manager for the entire project, specifying a comprehensive set of libraries and tools required to run the codebase<br>- It enables seamless integration with various technologies, including machine learning frameworks, data analysis tools, and web development platforms<br>- By fulfilling these dependencies, the codebase can be efficiently executed, tested, and deployed across different environments.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/Makefile'>Makefile</a></b></td>
					<td style='padding: 8px;'>- Automates Code Quality and Cleanup**The Makefile serves as the backbone of the projects build and maintenance process<br>- It orchestrates tasks such as code styling, linting, and cleanup to ensure consistency and adherence to coding standards<br>- By running these commands, developers can maintain a clean and organized codebase, while also leveraging tools like flake8 and isort for quality assurance.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/pyproject.toml'>pyproject.toml</a></b></td>
					<td style='padding: 8px;'>- Automates Code Formatting and Testing**The provided pyproject.toml file configures the projects formatting and testing tools to ensure consistency across the codebase<br>- It utilizes Black, iSort, Flake8, and Pytest to enforce coding standards, run tests, and measure coverage, ultimately maintaining a high-quality architecture for the entire codebase.</td>
				</tr>
			</table>
		</blockquote>
	</details>
	<!-- deploy Submodule -->
	<details>
		<summary><b>deploy</b></summary>
		<blockquote>
			<div class='directory-path' style='padding: 8px 0; color: #666;'>
				<code><b>⦿ deploy</b></code>
			<table style='width: 100%; border-collapse: collapse;'>
			<thead>
				<tr style='background-color: #f8f9fa;'>
					<th style='width: 30%; text-align: left; padding: 8px;'>File Name</th>
					<th style='text-align: left; padding: 8px;'>Summary</th>
				</tr>
			</thead>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/deploy/cluster_env.yaml'>cluster_env.yaml</a></b></td>
					<td style='padding: 8px;'>- Deploy the cluster environment by running <code>kubectl apply-f deploy/cluster_env.yaml</code><br>- The file configures a base image and sets up dependencies for a Ray-based project, ensuring compatibility with the specified Python version<br>- It also installs required packages via pip, setting the stage for a streamlined development workflow within the Made-With-ML project.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/deploy/cluster_compute.yaml'>cluster_compute.yaml</a></b></td>
					<td style='padding: 8px;'>- Deploy Cluster ConfigurationThe <code>cluster_compute.yaml</code> file defines the architecture for a cloud-based cluster, specifying the region and instance types for head and worker nodes<br>- It configures AWS resources, including block device mappings and tags, to support a multi-zone environment with a specific feature set<br>- The resulting configuration enables the deployment of a scalable and efficient cluster for machine learning workloads in the specified region.</td>
				</tr>
			</table>
			<!-- jobs Submodule -->
			<details>
				<summary><b>jobs</b></summary>
				<blockquote>
					<div class='directory-path' style='padding: 8px 0; color: #666;'>
						<code><b>⦿ deploy.jobs</b></code>
					<table style='width: 100%; border-collapse: collapse;'>
					<thead>
						<tr style='background-color: #f8f9fa;'>
							<th style='width: 30%; text-align: left; padding: 8px;'>File Name</th>
							<th style='text-align: left; padding: 8px;'>Summary</th>
						</tr>
					</thead>
						<tr style='border-bottom: 1px solid #eee;'>
							<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/deploy/jobs/workloads.yaml'>workloads.yaml</a></b></td>
							<td style='padding: 8px;'>- The <code>workloads.yaml</code> file orchestrates the deployment of workload jobs to a managed Kubernetes cluster, <code>madewithml-cluster-env</code>, using a custom compute configuration and runtime environment<br>- It defines project settings, such as <code>project_id</code> and <code>cluster_env</code>, and specifies an entrypoint script for job execution<br>- This file enables automated deployment and management of workload jobs within the project.</td>
						</tr>
						<tr style='border-bottom: 1px solid #eee;'>
							<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/deploy/jobs/workloads.sh'>workloads.sh</a></b></td>
							<td style='padding: 8px;'>- Automates End-to-End Model Deployment and Evaluation**The <code>workloads.sh</code> file orchestrates the deployment and evaluation of a machine learning model using the MadewithML framework<br>- It executes tests, trains a model, evaluates its performance, and saves the trained model to an AWS S3 bucket<br>- The script also generates run IDs for serving later.</td>
						</tr>
					</table>
				</blockquote>
			</details>
			<!-- services Submodule -->
			<details>
				<summary><b>services</b></summary>
				<blockquote>
					<div class='directory-path' style='padding: 8px 0; color: #666;'>
						<code><b>⦿ deploy.services</b></code>
					<table style='width: 100%; border-collapse: collapse;'>
					<thead>
						<tr style='background-color: #f8f9fa;'>
							<th style='width: 30%; text-align: left; padding: 8px;'>File Name</th>
							<th style='text-align: left; padding: 8px;'>Summary</th>
						</tr>
					</thead>
						<tr style='border-bottom: 1px solid #eee;'>
							<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/deploy/services/serve_model.yaml'>serve_model.yaml</a></b></td>
							<td style='padding: 8px;'>- Deploy Service Configuration**Configures the deployment of a model serving service using Ray Serve<br>- The configuration defines the project ID, cluster environment, and compute configuration, as well as the import path and runtime environment for the serve_model entrypoint<br>- The rollout strategy is set to ROLLOUT, specifying how the service should be deployed<br>- This file serves as a critical component of the overall codebase architecture, enabling model serving capabilities.</td>
						</tr>
						<tr style='border-bottom: 1px solid #eee;'>
							<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/deploy/services/serve_model.py'>serve_model.py</a></b></td>
							<td style='padding: 8px;'>- The <code>serve_model.py</code> file serves as the entrypoint for model deployment, utilizing the <code>ModelDeployment</code> class to bind a run ID and threshold value<br>- It copies necessary model files from an S3 bucket and updates local directories with results<br>- This script enables the model to be served and accessed through the deployed service, facilitating model evaluation and testing.</td>
						</tr>
					</table>
				</blockquote>
			</details>
		</blockquote>
	</details>
	<!-- madewithml Submodule -->
	<details>
		<summary><b>madewithml</b></summary>
		<blockquote>
			<div class='directory-path' style='padding: 8px 0; color: #666;'>
				<code><b>⦿ madewithml</b></code>
			<table style='width: 100%; border-collapse: collapse;'>
			<thead>
				<tr style='background-color: #f8f9fa;'>
					<th style='width: 30%; text-align: left; padding: 8px;'>File Name</th>
					<th style='text-align: left; padding: 8px;'>Summary</th>
				</tr>
			</thead>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/madewithml/config.py'>config.py</a></b></td>
					<td style='padding: 8px;'>- Configures logging settings for the project, setting up multiple log handlers to handle console output, info logs, and error logs, with rotating file backups<br>- Establishes a base configuration for logging across the entire codebase, providing a standardized approach to handling various types of log messages.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/madewithml/models.py'>models.py</a></b></td>
					<td style='padding: 8px;'>- Fine-tunes a Large Language Model (LLM) by adding a classification layer on top of the models output<br>- The architecture is designed to handle sequential data and incorporates dropout regularization to prevent overfitting<br>- The model achieves this by processing input sequences, applying attention mechanisms, and transforming the output through a fully connected layer.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/madewithml/predict.py'>predict.py</a></b></td>
					<td style='padding: 8px;'>- Predicts project tags based on input features using pre-trained machine learning models stored in a checkpoint<br>- The <code>predict</code> command loads the best-performing model from an MLflow experiment, processes input data, and returns predicted labels with probabilities<br>- It supports loading specific runs and customizing prediction settings.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/madewithml/serve.py'>serve.py</a></b></td>
					<td style='padding: 8px;'>- Deploying Machine Learning Models**The <code>serve.py</code> file serves as the entry point for deploying a machine learning model using Ray and FastAPI<br>- It initializes a deployment of the <code>ModelDeployment</code> class, which loads a trained model from MLFlow and provides endpoints for health checks, run ID retrieval, evaluation, and prediction<br>- The code achieves this by setting up an HTTP server that can handle incoming requests and interact with the loaded model.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/madewithml/utils.py'>utils.py</a></b></td>
					<td style='padding: 8px;'>- Replicate and manage data pipelines efficiently with the <code>utils.py</code> file<br>- This utility module provides functions to load and save dictionaries, pad arrays, convert batches to tensors, and retrieve MLflow run IDs<br>- It facilitates reproducibility by setting seeds and ensures data consistency through padding and sorting<br>- The code enables seamless integration with Rays data and training frameworks.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/madewithml/tune.py'>tune.py</a></b></td>
					<td style='padding: 8px;'>- Optimize Hyperparameter Tuning Experiment=====================================The <code>tune.py</code> file serves as the main entry point for hyperparameter tuning experiments using Ray Tune<br>- It orchestrates the training process, scaling, and search algorithms to find optimal hyperparameters for a given model<br>- The script initializes the Ray environment, sets up the training loop configuration, and defines the search algorithm, parameters, and scheduler.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/madewithml/train.py'>train.py</a></b></td>
					<td style='padding: 8px;'>- The provided code is a Ray Air training script that trains a model as a distributed workload<br>- It sets up the necessary configurations, including scaling and checkpointing, and runs the training process using the <code>TorchTrainer</code> class<br>- The script also includes logging and saving of results to an specified file path.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/madewithml/evaluate.py'>evaluate.py</a></b></td>
					<td style='padding: 8px;'>- Evaluate Model Performance Metrics=====================================The <code>evaluate.py</code> file provides a comprehensive evaluation framework for machine learning models<br>- It loads a dataset, retrieves the best checkpoint of a model run, and calculates performance metrics such as precision, recall, F1 score, and class-wise metrics<br>- The code also supports evaluating slices of data based on predefined criteria, making it suitable for large-scale model evaluations.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/madewithml/data.py'>data.py</a></b></td>
					<td style='padding: 8px;'>- Load data into a Ray Dataset, enabling efficient and scalable processing of large datasets<br>- The <code>load_data</code> function loads data from a specified location, allowing users to customize the number of samples to load<br>- This functionality is crucial for building machine learning models that rely on high-quality training data<br>- It sets the stage for further data preprocessing and modeling tasks.</td>
				</tr>
			</table>
		</blockquote>
	</details>
	<!-- .github Submodule -->
	<details>
		<summary><b>.github</b></summary>
		<blockquote>
			<div class='directory-path' style='padding: 8px 0; color: #666;'>
				<code><b>⦿ .github</b></code>
			<!-- workflows Submodule -->
			<details>
				<summary><b>workflows</b></summary>
				<blockquote>
					<div class='directory-path' style='padding: 8px 0; color: #666;'>
						<code><b>⦿ .github.workflows</b></code>
					<table style='width: 100%; border-collapse: collapse;'>
					<thead>
						<tr style='background-color: #f8f9fa;'>
							<th style='width: 30%; text-align: left; padding: 8px;'>File Name</th>
							<th style='text-align: left; padding: 8px;'>Summary</th>
						</tr>
					</thead>
						<tr style='border-bottom: 1px solid #eee;'>
							<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/.github/workflows/serve.yaml'>serve.yaml</a></b></td>
							<td style='padding: 8px;'>- Deploy Model Service**The <code>serve.yaml</code> file orchestrates the deployment of a model service using GitHub Actions<br>- It sets up AWS credentials, installs dependencies, and serves a model by running the <code>anyscale</code> command<br>- The workflow is triggered on push events to the main branch, allowing for automated model deployments.</td>
						</tr>
						<tr style='border-bottom: 1px solid #eee;'>
							<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/.github/workflows/json_to_md.py'>json_to_md.py</a></b></td>
							<td style='padding: 8px;'>- Converts JSON data to Markdown format, generating structured output with nested keys and values<br>- Converts a JSON file to a Markdown file, preserving key-value pairs and formatting complex data structures<br>- Used to automate the conversion of JSON files to Markdown files, useful for documentation and reporting purposes.</td>
						</tr>
						<tr style='border-bottom: 1px solid #eee;'>
							<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/.github/workflows/workloads.yaml'>workloads.yaml</a></b></td>
							<td style='padding: 8px;'>- Automates Workload Deployment and Results Analysis**The provided YAML file orchestrates a workflow that deploys workload jobs to AnyScale, a cloud-based machine learning platform, and analyzes the results<br>- The workflow dispatches on pull requests and manual triggers, leveraging AWS credentials and dependencies such as Python and pip<br>- It then submits the deployment job, reads results from S3, and comments training and evaluation results on the associated pull request.</td>
						</tr>
						<tr style='border-bottom: 1px solid #eee;'>
							<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/.github/workflows/documentation.yaml'>documentation.yaml</a></b></td>
							<td style='padding: 8px;'>- Generate Documentation Automatically=====================================The <code>documentation.yaml</code> file automates the build and deployment of project documentation using MkDocs<br>- It triggers a workflow on push events to the main branch, installing required dependencies and deploying the generated documentation to GitHub Pages<br>- This enables seamless updates and visibility for users, ensuring the projects documentation remains up-to-date and easily accessible.</td>
						</tr>
					</table>
				</blockquote>
			</details>
		</blockquote>
	</details>
	<!-- notebooks Submodule -->
	<details>
		<summary><b>notebooks</b></summary>
		<blockquote>
			<div class='directory-path' style='padding: 8px 0; color: #666;'>
				<code><b>⦿ notebooks</b></code>
			<table style='width: 100%; border-collapse: collapse;'>
			<thead>
				<tr style='background-color: #f8f9fa;'>
					<th style='width: 30%; text-align: left; padding: 8px;'>File Name</th>
					<th style='text-align: left; padding: 8px;'>Summary</th>
				</tr>
			</thead>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/notebooks/benchmarks.ipynb'>benchmarks.ipynb</a></b></td>
					<td style='padding: 8px;'>- Summary<strong>The <code>benchmarks.ipynb</code> file serves as a central repository for performance benchmarking and testing of the entire codebase<br>- It provides a standardized framework for evaluating the scalability, efficiency, and reliability of the project's components.By executing this notebook, developers can gain insights into the overall performance characteristics of their code, identify areas for optimization, and ensure that changes do not negatively impact existing functionality.</strong>Key Benefits<em>*</em> Standardized benchmarking framework<em> Comprehensive evaluation of codebase performance</em> Identification of optimization opportunities* Ensures code reliability and scalabilityThis notebook is an essential component of the projects architecture, providing a unified approach to testing and evaluating the entire codebase.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/GokuMohandas/mlops-course/blob/master/notebooks/madewithml.ipynb'>madewithml.ipynb</a></b></td>
					<td style='padding: 8px;'>Provides an introduction to the Made With ML platform, highlighting its core values and mission.<em> Offers a high-level overview of the project's structure and architecture.</em> Serves as a starting point for developers to explore the platform's features and capabilities.By utilizing this codebase, users can gain insights into the overall design and functionality of the Made With ML platform, ultimately facilitating their own development journey in machine learning.</td>
				</tr>
			</table>
		</blockquote>
	</details>
</details>

---

## 🌟 Getting Started

### 💠 Prerequisites

This project requires the following dependencies:

- **Programming Language:** Python
- **Package Manager:** Pip

### 🔷 Installation

Build mlops-course from the source and install dependencies:

1. **Clone the repository:**

    ```sh
    ❯ git clone https://github.com/GokuMohandas/mlops-course
    ```

2. **Navigate to the project directory:**

    ```sh
    ❯ cd mlops-course
    ```

3. **Install the dependencies:**

<!-- SHIELDS BADGE CURRENTLY DISABLED -->
	<!-- [![pip][pip-shield]][pip-link] -->
	<!-- REFERENCE LINKS -->
	<!-- [pip-shield]: https://img.shields.io/badge/Pip-3776AB.svg?style={badge_style}&logo=pypi&logoColor=white -->
	<!-- [pip-link]: https://pypi.org/project/pip/ -->

	**Using [pip](https://pypi.org/project/pip/):**

	```sh
	❯ pip install -r requirements.txt
	```


### 🔸 Usage

Run the project with:

**Using [pip](https://pypi.org/project/pip/):**
```sh
python {entrypoint}
```

### ✴️ Testing

Mlops-course uses the {__test_framework__} test framework. Run the test suite with:

**Using [pip](https://pypi.org/project/pip/):**
```sh
pytest
```


---

## ⚡ Roadmap

- [X] **`Task 1`**: <strike>Implement feature one.</strike>
- [ ] **`Task 2`**: Implement feature two.
- [ ] **`Task 3`**: Implement feature three.

---

## 🌀 Contributing

- **💬 [Join the Discussions](https://github.com/GokuMohandas/mlops-course/discussions)**: Share your insights, provide feedback, or ask questions.
- **🐛 [Report Issues](https://github.com/GokuMohandas/mlops-course/issues)**: Submit bugs found or log feature requests for the `mlops-course` project.
- **💡 [Submit Pull Requests](https://github.com/GokuMohandas/mlops-course/blob/main/CONTRIBUTING.md)**: Review open PRs, and submit your own PRs.

<details closed>
<summary>Contributing Guidelines</summary>

1. **Fork the Repository**: Start by forking the project repository to your github account.
2. **Clone Locally**: Clone the forked repository to your local machine using a git client.
   ```sh
   git clone https://github.com/GokuMohandas/mlops-course
   ```
3. **Create a New Branch**: Always work on a new branch, giving it a descriptive name.
   ```sh
   git checkout -b new-feature-x
   ```
4. **Make Your Changes**: Develop and test your changes locally.
5. **Commit Your Changes**: Commit with a clear message describing your updates.
   ```sh
   git commit -m 'Implemented new feature x.'
   ```
6. **Push to github**: Push the changes to your forked repository.
   ```sh
   git push origin new-feature-x
   ```
7. **Submit a Pull Request**: Create a PR against the original project repository. Clearly describe the changes and their motivations.
8. **Review**: Once your PR is reviewed and approved, it will be merged into the main branch. Congratulations on your contribution!
</details>

<details closed>
<summary>Contributor Graph</summary>
<br>
<p align="left">
   <a href="https://github.com{/GokuMohandas/mlops-course/}graphs/contributors">
      <img src="https://contrib.rocks/image?repo=GokuMohandas/mlops-course">
   </a>
</p>
</details>

---

## 💫 License

Mlops-course is protected under the [LICENSE](https://choosealicense.com/licenses) License. For more details, refer to the [LICENSE](https://choosealicense.com/licenses/) file.

---

## ✧ Acknowledgments

- Credit `contributors`, `inspiration`, `references`, etc.

<div align="left"><a href="#top">⬆ Return</a></div>

---

<!-- README-AI COMMAND: -->
<!--
```sh
readmeai \
    --repository 'https://github.com/GokuMohandas/mlops-course' \
    --output 'docs/docs/examples/ai-providers/ollama/llama3/readme-mlops-course.md' \
    --badge-style 'for-the-badge' \
    --badge-color '000080' \
    --logo 'PURPLE' \
    --header-style 'COMPACT' \
    --navigation-style 'BULLET' \
    --emojis 'atomic' \
    --temperature 0.378 \
    --tree-max-depth 1 \
    --api ollama \
    --model llama3.2:latest
```
-->
